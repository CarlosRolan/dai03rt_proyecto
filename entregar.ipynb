{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fc9b057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "28459686",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUKECT_NAME = \"dai03rt-proyecto\"\n",
    "ACCESS_KEY_ID = \"AKIAWZEDMKF3SHFDRH3B\"\n",
    "SECRET_KEY = \"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\"\n",
    "REGION = \"eu-west-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4919b4f",
   "metadata": {},
   "source": [
    "## TMDB API\n",
    "\n",
    "Para el recopilado de datos usaremos las siguientes enpoints de TMDB:\n",
    "\n",
    "- #### DISCOVER: https://api.themoviedb.org/3/discover/movie\n",
    "    * Esta endpoints nos da una lista de peliculas aleatorias determinando una variedad de filtros\n",
    "    * Nuestro modelo ha sido entrenado con peliculas de hace 20 años, por lo que nuestro fitro debe ser ese rango de fechas\n",
    "    * De esta lista solo nos interesa el **ID** de cada pelicula ya que necesitamos usar otro endpoint para conseguir toda la info necesaria de cada peli\n",
    "    * Toda la información es paginada asi que por ese rango de fechas la request no da la info, solo de la primera pagina, teniendo que hacer una request por cada pagina restante hasta alcanzar el nº max_pages de esa request especifica\n",
    "\n",
    ">**PROBLEMA:**La propia API nos trunquea todas aquellas paginas por encima del numero 500, por lo que nos obliga a que nuestro rango de fechas nunca produzca una request con un numero de paginas superior. Debido a esto hemos tenido que crear unos rangos de fechas especificos, que partimos en request con un step determinado, uno para cada rango. Esto se debe a que la producción de las peliculas es una distribución compleja\n",
    "\n",
    "- #### DETAILS_MOVIES: https://api.themoviedb.org/3/movie/{movie_id}\n",
    "    * Una vez tenemos todos los ids de nuestras peliculas, haremos una peticion a este endpoint por cada id\n",
    "    * Ahora si tenemos toda la info encesaria como, los actores qeu ahn trabajado en la peli, los generos, el presupuesto, la recaudación, etc\n",
    "\n",
    "- #### DETAILS_ACTORS https://api.themoviedb.org/3/person/{person_id}\n",
    "    * Con los ids de los actores recopilados gracias a la anterior url, podemos generar una lista, sin actores repetidos, de los ids de cada actor para buscar sus detalles\n",
    "    * Debido a esto nuestro flujo simpre necesita primero conocer los detalles de las paliculas antes de conocer los detalles de cada actor\n",
    "\n",
    "- #### GENRE_LIST https://api.themoviedb.org/3/genre/movie/list\n",
    "    * En esta enpoint recogemos todos los generos posibles que pueden tener las peliculas\n",
    "    * Cabe recordar que una pelicula puede tener varios generos, y que un genero puede encontrarse en varios peliculas por supuesto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2769a062",
   "metadata": {},
   "source": [
    "## LAMBDAS\n",
    "\n",
    "![Alt](./img/lambdas.png \"Propiedades del BUCKET\")\n",
    "\n",
    "- init_tmdb: funcion que crea en nuestra instancia RDS la base de datos y el usuario que la gestiona\n",
    "- create_tables_tmdb: funcion que crea la estructura de la base de datos\n",
    "- funcion_diaria: funcion de recogida y guardado de nuevos datos cada dia\n",
    "- send_query: funcion para ejecutar queries de tipo DML, en concreto generadoras de vistas\n",
    "- funcion_inicial: funcion de carga incial de peliculas\n",
    "- insert_data_tmdb | Runtime: python3.11 | Última modif: 2025-09-21T15:30:09.000+0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69abeac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = boto3.client(\"lambda\",\n",
    "                  aws_access_key_id = ACCESS_KEY_ID,\n",
    "                  aws_secret_access_key = SECRET_KEY,\n",
    "                  region_name=REGION) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0037f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Listar funciones Lambda existentes\n",
    "\n",
    "def invoke_lambda_inicial(payload: dict, async_: bool = False):\n",
    "    \"\"\"Invoca la lambda con el payload dado (sync por defecto).\"\"\"\n",
    "    resp = lambda_.invoke(\n",
    "        FunctionName=\"funcion_inicial\",\n",
    "        InvocationType=\"Event\" if async_ else \"RequestResponse\",\n",
    "        Payload=json.dumps(payload).encode(\"utf-8\"),\n",
    "    )\n",
    "    if async_:\n",
    "        print(\"✔ Invocación async enviada.\")\n",
    "        return None\n",
    "    print(\"HTTP Status:\", resp.get(\"StatusCode\"))\n",
    "    body = resp.get(\"Payload\").read().decode(\"utf-8\")\n",
    "    try:\n",
    "        print(\"Respuesta Lambda:\", json.loads(body))\n",
    "    except Exception:\n",
    "        print(\"Respuesta Lambda (raw):\", body)\n",
    "\n",
    "\n",
    "def listar_funciones():\n",
    "    response = lambda_.list_functions()\n",
    "    for f in response['Functions']:\n",
    "        print(f\"{f['FunctionName']} | Runtime: {f['Runtime']} | Última modif: {f['LastModified']}\")\n",
    "        \n",
    "def invocar_lambda(nombre_funcion, payload={}):\n",
    "    try:\n",
    "        response = lambda_.invoke(\n",
    "            FunctionName=nombre_funcion,\n",
    "            InvocationType='RequestResponse',\n",
    "            Payload=json.dumps(payload),\n",
    "        )\n",
    "        print(\"Respuesta:\")\n",
    "        result_raw = (response['Payload']).read().decode('utf-8')\n",
    "        result = json.loads(result_raw)\n",
    "        print(result)\n",
    "        return result\n",
    "    except ClientError as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da0769c",
   "metadata": {},
   "source": [
    "## ESTRUCTURA S3\n",
    "\n",
    "![Alt](./img/bucket_info.png \"Lista de lambdas\")\n",
    "\n",
    "- initial_load: carpeta donde guardaremos todos los datos de peliculas, actores y generos\n",
    "    - **__/movies**: a su vez dividida por carpetas de ventanas\n",
    "\n",
    "        - /date_range_X: donde x es un numero no una fecha\n",
    "            - /ventana_x/: guarda uno o varios ficheros de los detalles de las peliculas en un  rango de fechas\n",
    "                - X_movie.json: el fichero en si (a veces son varios pues se ha tenido que partir) \n",
    "    \n",
    "    - **__/actors__/**: lo ficheros de todos los actores que participan en las peliculas\n",
    "        - X_actors.json no suele tener mas de 500 actores por fichero\n",
    "    \n",
    "    - **__/genres/**:\n",
    "        - **genres_list.json: unico fichero donde se guarda la lista de géneros disponible\n",
    "\n",
    "\n",
    "- dayly_update: carpeta donde se guardan temporalmente los datos a actualizar, se llama cada día por la mañana  \n",
    "    - movies:\n",
    "        X_new_movies.json\n",
    "    - actors:\n",
    "        X_new_actors.json\n",
    "    - genres:\n",
    "        new_genres.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d005d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\",\n",
    "                  aws_access_key_id = ACCESS_KEY_ID,\n",
    "                  aws_secret_access_key = SECRET_KEY,\n",
    "                  region_name=REGION) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f0088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones auxiliares para cargar los datos de s3\n",
    "\n",
    "def load_all_movies_records(prefix_root: str = \"initial_load/movies/\") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Lee TODOS los Parquet bajo:\n",
    "      {prefix_root}/date_range_*/ventana_*/{n}_movies.parquet\n",
    "    y devuelve una lista de diccionarios (records).\n",
    "    \"\"\"\n",
    "    prefix = prefix_root.rstrip(\"/\") + \"/\"\n",
    "\n",
    "    # Listar todas las claves .parquet bajo el prefijo\n",
    "    keys = []\n",
    "    paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "    for page in paginator.paginate(Bucket=BUKECT_NAME, Prefix=prefix):\n",
    "        for obj in page.get(\"Contents\", []):\n",
    "            k = obj[\"Key\"]\n",
    "            if k.endswith(\".parquet\"):\n",
    "                keys.append(k)\n",
    "\n",
    "    keys.sort()  # lectura determinista (opcional)\n",
    "\n",
    "    # Cargar y acumular\n",
    "    records: list[dict] = []\n",
    "    for key in keys:\n",
    "        body = s3.get_object(Bucket=BUKECT_NAME, Key=key)[\"Body\"].read()\n",
    "        table = pq.read_table(io.BytesIO(body))\n",
    "        records.extend(table.to_pylist())  # lista de dicts por fila\n",
    "\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f152b354",
   "metadata": {},
   "source": [
    "## CARGA DE DATOS\n",
    "\n",
    "La carga de datos se realiza a traves de varias funciones lambdas de aws:\n",
    "\n",
    "- \"fucion_incial\n",
    "- funcion_diaria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5872215c",
   "metadata": {},
   "source": [
    "#### FUNCION INCIAL\n",
    "\n",
    "Se encarga de conseguir todos los ids de las peliculas en un rango de fechas\n",
    "- Por ejemplo las fechas 2005, 1, 1 hasta 2010, 12, 31\n",
    "- Este rango se partirá a su vez en en rangos de fechas mas pequeños con la longitud marcada por el step, en este caso 182 días.\n",
    "- Estos nuevos rangos los lllamamos ventantas y represenan la agrupacion de fechas entre 2005, 1, 1 hasta 2010, 12, 31, pero con una longitud de 182 (a excepcion de la última que no suele coincidir un step perfecto)\n",
    "- En cada ventana tenemos un nuemor de paginas totales\n",
    "- En cada pagina tenemos 20 peliculas\n",
    "- Cuando tenemos todos los ids de todas las paginas de una ventana, se hara un request a details de movies y cuando hayamos conseguido los detalles de todas las peliculas de todas las paginas de esa ventana en concreto se guardara un archvio en s3 con los detalles de las (20xN_paginas_totales) peliculas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4f68dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rangos_step = [\n",
    "    (date(2005, 1, 1),  date(2010, 12, 31), 182),\n",
    "    (date(2011, 1, 1),  date(2013, 9, 16),  120),\n",
    "    (date(2013, 9, 17), date(2014, 1, 6),   100),\n",
    "    (date(2014, 1, 7),  date(2015, 12, 31), 110),\n",
    "    (date(2016, 1, 1),  date(2021, 12, 31), 70),\n",
    "    (date(2022, 1, 1),  date(2024, 10, 16), 60),\n",
    "    (date(2024, 10, 17),date(2024, 12, 16), 30),\n",
    "    (date(2024, 12, 17),date.today(),       60),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbc0b33",
   "metadata": {},
   "source": [
    "## RDS: Preparación de la instancia RDS\n",
    "\n",
    "![Alt](./img/rds.png \"Propiedades del RDS\")\n",
    "\n",
    "Antes de empezar a usar nuestra instancia de RDS necesitamos:\n",
    "- Crear la base de datos y un usuario que la vaya gestionar\n",
    "- Crear la estructura de las tablas y sus relaciones\n",
    "- Insertar todos los datos inciales (Guardados en s3 __initial_load/*/__) \n",
    "- Insertar o modificar los nuevos datos (Guardados en dayly/movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942ad484",
   "metadata": {},
   "source": [
    "### RDS.1 Primero inicializamos nuestra base de datos\n",
    "\n",
    "DOCUMENTACION: **./lambdas/init_tmdb**\n",
    "\n",
    "Para ello llamamos a la LAMBDA __\"init_tmdb\"__ que hace lo siguinte:\n",
    "\n",
    "- Creamos una base de datos \"tmdb\" \n",
    "- Creamos un usuario \"user\" que será el que maneje las tablas\n",
    "    * Este usuario **NO** podrá eliminar la base de datos por seguridad\n",
    "    * Podrá crear nuevas tablas y borrarlas pero nunca la base de datos entera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ca722f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rangos_step = [\n",
    "    (date(2005, 1, 1),  date(2010, 12, 31), 182),\n",
    "    (date(2011, 1, 1),  date(2013, 9, 16),  120),\n",
    "    (date(2013, 9, 17), date(2014, 1, 6),   100),\n",
    "    (date(2014, 1, 7),  date(2015, 12, 31), 110),\n",
    "    (date(2016, 1, 1),  date(2021, 12, 31), 70),\n",
    "    (date(2022, 1, 1),  date(2024, 10, 16), 60),\n",
    "    (date(2024, 10, 17),date(2024, 12, 16), 30),\n",
    "    (date(2024, 12, 17),date.today(),       60),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef1227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date_range_n = 1\n",
    "for f_incial, f_final, step in rangos_step:\n",
    "    date_range_n += 1\n",
    "    f_from = f_incial.strftime(\"%Y-%m-%d\")\n",
    "    f_to = f_final.strftime(\"%Y-%m-%d\")\n",
    "    payload = {\n",
    "        \"from\": f_from,\n",
    "        \"to\":   f_to,\n",
    "        \"step_days\": step,\n",
    "        \"date_range_idx\": date_range_n\n",
    "    }\n",
    "    invoke_lambda_inicial(payload, async_=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc24dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Invocación async enviada.\n",
      "✔ Invocación async enviada.\n",
      "✔ Invocación async enviada.\n",
      "✔ Invocación async enviada.\n",
      "✔ Invocación async enviada.\n",
      "✔ Invocación async enviada.\n",
      "✔ Invocación async enviada.\n",
      "✔ Invocación async enviada.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afd5f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"from\": \"2005-01-01\",\n",
    "    \"to\":   \"2010-12-31\",\n",
    "    \"step_days\": 182,\n",
    "    \"date_range_idx\": 1 \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7909df94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8f82f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movies = load_all_movies_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4194a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>original_language</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>/26OvB15pqk3eiKJG8LrXDVzO7Mw.jpg</td>\n",
       "      <td>{'backdrop_path': '/44TlYuWbWBpRY3i0Ch7MJtLv4Y...</td>\n",
       "      <td>100000000</td>\n",
       "      <td>[{'id': 14, 'name': 'Fantasy'}, {'id': 28, 'na...</td>\n",
       "      <td>https://www.warnerbros.com/movies/constantine</td>\n",
       "      <td>561</td>\n",
       "      <td>tt0360486</td>\n",
       "      <td>[US]</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>2005-02-08</td>\n",
       "      <td>230900000</td>\n",
       "      <td>121</td>\n",
       "      <td>[{'english_name': 'Spanish', 'iso_639_1': 'es'...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Hell wants him. Heaven won't take him. Earth n...</td>\n",
       "      <td>Constantine</td>\n",
       "      <td>False</td>\n",
       "      <td>7.100</td>\n",
       "      <td>7613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>/2YJOXPl4QtCskixYA58ToyCXEW0.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>110000000</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 35, 'nam...</td>\n",
       "      <td></td>\n",
       "      <td>787</td>\n",
       "      <td>tt0356910</td>\n",
       "      <td>[US]</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>2005-06-07</td>\n",
       "      <td>487287646</td>\n",
       "      <td>119</td>\n",
       "      <td>[{'english_name': 'English', 'iso_639_1': 'en'...</td>\n",
       "      <td>Released</td>\n",
       "      <td>'Til death do us part.</td>\n",
       "      <td>Mr. &amp; Mrs. Smith</td>\n",
       "      <td>False</td>\n",
       "      <td>6.688</td>\n",
       "      <td>10791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>/vzeyPbl4rWMVgdkAj7thmDuQZmE.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...</td>\n",
       "      <td>http://www.cbs.com/specials/magic_of_ordinary_...</td>\n",
       "      <td>47525</td>\n",
       "      <td>tt0406046</td>\n",
       "      <td>[US]</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>2005-01-30</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>[{'english_name': 'English', 'iso_639_1': 'en'...</td>\n",
       "      <td>Released</td>\n",
       "      <td></td>\n",
       "      <td>The Magic of Ordinary Days</td>\n",
       "      <td>False</td>\n",
       "      <td>7.400</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>/bInicBgSHfQiWLbnRT5jxw9Grvm.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>132000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 53, '...</td>\n",
       "      <td>https://amblin.com/movie/war-of-the-worlds/</td>\n",
       "      <td>74</td>\n",
       "      <td>tt0407304</td>\n",
       "      <td>[US]</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>2005-06-28</td>\n",
       "      <td>603873119</td>\n",
       "      <td>117</td>\n",
       "      <td>[{'english_name': 'English', 'iso_639_1': 'en'...</td>\n",
       "      <td>Released</td>\n",
       "      <td>They're already here.</td>\n",
       "      <td>War of the Worlds</td>\n",
       "      <td>False</td>\n",
       "      <td>6.522</td>\n",
       "      <td>8742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>/1WRwy3EDc2LVtwauzIMMGVJLEI5.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>25000000</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "      <td>http://www.sonypictures.com/movies/lordsofdogtown</td>\n",
       "      <td>9787</td>\n",
       "      <td>tt0355702</td>\n",
       "      <td>[US]</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>2005-06-03</td>\n",
       "      <td>13411957</td>\n",
       "      <td>107</td>\n",
       "      <td>[{'english_name': 'English', 'iso_639_1': 'en'...</td>\n",
       "      <td>Released</td>\n",
       "      <td>They came from nothing to change everything.</td>\n",
       "      <td>Lords of Dogtown</td>\n",
       "      <td>False</td>\n",
       "      <td>7.102</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35474</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 99, 'name': 'Documentary'}]</td>\n",
       "      <td></td>\n",
       "      <td>41329</td>\n",
       "      <td>tt1339141</td>\n",
       "      <td>[US]</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td></td>\n",
       "      <td>Overdrawn!</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35475</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>30705</td>\n",
       "      <td></td>\n",
       "      <td>[US]</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>2007-03-07</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>[{'english_name': 'Norwegian', 'iso_639_1': 'n...</td>\n",
       "      <td>Released</td>\n",
       "      <td></td>\n",
       "      <td>Ka e vitsen?</td>\n",
       "      <td>False</td>\n",
       "      <td>7.500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35476</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>52478</td>\n",
       "      <td>tt0768192</td>\n",
       "      <td>[US]</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[{'english_name': 'German', 'iso_639_1': 'de',...</td>\n",
       "      <td>Released</td>\n",
       "      <td></td>\n",
       "      <td>Die Handwerker Gottes</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35477</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>23181</td>\n",
       "      <td></td>\n",
       "      <td>[US]</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'english_name': 'German', 'iso_639_1': 'de',...</td>\n",
       "      <td>Released</td>\n",
       "      <td></td>\n",
       "      <td>prediculous</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35478</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>{'backdrop_path': None, 'id': 181403, 'name': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>53107</td>\n",
       "      <td></td>\n",
       "      <td>[US]</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td></td>\n",
       "      <td>Earthed 4 - Death or Glory</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35479 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adult                     backdrop_path  \\\n",
       "0      False  /26OvB15pqk3eiKJG8LrXDVzO7Mw.jpg   \n",
       "1      False  /2YJOXPl4QtCskixYA58ToyCXEW0.jpg   \n",
       "2      False  /vzeyPbl4rWMVgdkAj7thmDuQZmE.jpg   \n",
       "3      False  /bInicBgSHfQiWLbnRT5jxw9Grvm.jpg   \n",
       "4      False  /1WRwy3EDc2LVtwauzIMMGVJLEI5.jpg   \n",
       "...      ...                               ...   \n",
       "35474  False                              None   \n",
       "35475  False                              None   \n",
       "35476  False                              None   \n",
       "35477  False                              None   \n",
       "35478  False                              None   \n",
       "\n",
       "                                   belongs_to_collection     budget  \\\n",
       "0      {'backdrop_path': '/44TlYuWbWBpRY3i0Ch7MJtLv4Y...  100000000   \n",
       "1                                                   None  110000000   \n",
       "2                                                   None          0   \n",
       "3                                                   None  132000000   \n",
       "4                                                   None   25000000   \n",
       "...                                                  ...        ...   \n",
       "35474                                               None          0   \n",
       "35475                                               None          0   \n",
       "35476                                               None          0   \n",
       "35477                                               None          0   \n",
       "35478  {'backdrop_path': None, 'id': 181403, 'name': ...          0   \n",
       "\n",
       "                                                  genres  \\\n",
       "0      [{'id': 14, 'name': 'Fantasy'}, {'id': 28, 'na...   \n",
       "1      [{'id': 28, 'name': 'Action'}, {'id': 35, 'nam...   \n",
       "2      [{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...   \n",
       "3      [{'id': 12, 'name': 'Adventure'}, {'id': 53, '...   \n",
       "4                          [{'id': 18, 'name': 'Drama'}]   \n",
       "...                                                  ...   \n",
       "35474                [{'id': 99, 'name': 'Documentary'}]   \n",
       "35475                                                 []   \n",
       "35476                                                 []   \n",
       "35477                                                 []   \n",
       "35478                                                 []   \n",
       "\n",
       "                                                homepage     id    imdb_id  \\\n",
       "0          https://www.warnerbros.com/movies/constantine    561  tt0360486   \n",
       "1                                                           787  tt0356910   \n",
       "2      http://www.cbs.com/specials/magic_of_ordinary_...  47525  tt0406046   \n",
       "3            https://amblin.com/movie/war-of-the-worlds/     74  tt0407304   \n",
       "4      http://www.sonypictures.com/movies/lordsofdogtown   9787  tt0355702   \n",
       "...                                                  ...    ...        ...   \n",
       "35474                                                     41329  tt1339141   \n",
       "35475                                                     30705              \n",
       "35476                                                     52478  tt0768192   \n",
       "35477                                                     23181              \n",
       "35478                                                     53107              \n",
       "\n",
       "      origin_country original_language  ... release_date    revenue  runtime  \\\n",
       "0               [US]                en  ...   2005-02-08  230900000      121   \n",
       "1               [US]                en  ...   2005-06-07  487287646      119   \n",
       "2               [US]                en  ...   2005-01-30          0      120   \n",
       "3               [US]                en  ...   2005-06-28  603873119      117   \n",
       "4               [US]                en  ...   2005-06-03   13411957      107   \n",
       "...              ...               ...  ...          ...        ...      ...   \n",
       "35474           [US]                en  ...   2007-01-01          0       74   \n",
       "35475           [US]                en  ...   2007-03-07          0       92   \n",
       "35476           [US]                en  ...   2007-01-01          0       38   \n",
       "35477           [US]                en  ...   2007-01-01          0        0   \n",
       "35478           [US]                en  ...   2007-02-01          0       68   \n",
       "\n",
       "                                        spoken_languages    status  \\\n",
       "0      [{'english_name': 'Spanish', 'iso_639_1': 'es'...  Released   \n",
       "1      [{'english_name': 'English', 'iso_639_1': 'en'...  Released   \n",
       "2      [{'english_name': 'English', 'iso_639_1': 'en'...  Released   \n",
       "3      [{'english_name': 'English', 'iso_639_1': 'en'...  Released   \n",
       "4      [{'english_name': 'English', 'iso_639_1': 'en'...  Released   \n",
       "...                                                  ...       ...   \n",
       "35474                                                 []  Released   \n",
       "35475  [{'english_name': 'Norwegian', 'iso_639_1': 'n...  Released   \n",
       "35476  [{'english_name': 'German', 'iso_639_1': 'de',...  Released   \n",
       "35477  [{'english_name': 'German', 'iso_639_1': 'de',...  Released   \n",
       "35478                                                 []  Released   \n",
       "\n",
       "                                                 tagline  \\\n",
       "0      Hell wants him. Heaven won't take him. Earth n...   \n",
       "1                                 'Til death do us part.   \n",
       "2                                                          \n",
       "3                                  They're already here.   \n",
       "4           They came from nothing to change everything.   \n",
       "...                                                  ...   \n",
       "35474                                                      \n",
       "35475                                                      \n",
       "35476                                                      \n",
       "35477                                                      \n",
       "35478                                                      \n",
       "\n",
       "                            title  video  vote_average vote_count  \n",
       "0                     Constantine  False         7.100       7613  \n",
       "1                Mr. & Mrs. Smith  False         6.688      10791  \n",
       "2      The Magic of Ordinary Days  False         7.400         84  \n",
       "3               War of the Worlds  False         6.522       8742  \n",
       "4                Lords of Dogtown  False         7.102        773  \n",
       "...                           ...    ...           ...        ...  \n",
       "35474                  Overdrawn!  False         0.000          0  \n",
       "35475                Ka e vitsen?  False         7.500          2  \n",
       "35476       Die Handwerker Gottes  False         0.000          0  \n",
       "35477                 prediculous  False         0.000          0  \n",
       "35478  Earthed 4 - Death or Glory  False         0.000          0  \n",
       "\n",
       "[35479 rows x 26 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f95a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "invocar_lambda(nombre_funcion=\"init_tmdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9477ef0d",
   "metadata": {},
   "source": [
    "### RDS.2 Creamos la estrucutura de nuestra base de datos:\n",
    "\n",
    "DOCUMENTACION: **./lambdas/create_tables_tmdb**\n",
    "\n",
    "Llmamaos a la LAMBDA __\"create_tables_tmdb\"__. Creación de las tablas y de sus relaciones, la lambda ejecuta un archivo .sql guardado en el propio codigo de la lambda.\n",
    "\n",
    "Este es es archivo: \n",
    "\n",
    "```sql\n",
    "-- SCHEMA: tmdb (tablas en 'public')\n",
    "\n",
    "-- TABLE: movies\n",
    "CREATE TABLE IF NOT EXISTS public.movies (\n",
    "    id              INTEGER PRIMARY KEY,                      -- TMDB movie id (manual)\n",
    "    title           TEXT NOT NULL,\n",
    "    popularity      REAL,                                     -- float4\n",
    "    vote_average    NUMERIC(3,1) \n",
    "    CHECK (vote_average >= 0 AND vote_average <= 10),     -- 0.0..10.0\n",
    "    runtime         SMALLINT CHECK (runtime >= 0),            -- minutos\n",
    "    budget          BIGINT CHECK (budget  >= 0),              -- entero (unidades monetarias)\n",
    "    revenue         BIGINT CHECK (revenue >= 0),\n",
    "    overview        TEXT,\n",
    "    release_date    DATE,\n",
    "    success         BOOLEAN\n",
    ");\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS idx_movies_release_date ON public.movies (release_date);\n",
    "CREATE INDEX IF NOT EXISTS idx_movies_popularity  ON public.movies (popularity);\n",
    "CREATE INDEX IF NOT EXISTS idx_movies_title_lower ON public.movies (lower(title));\n",
    "\n",
    "-- TABLE: actors (cast)\n",
    "CREATE TABLE IF NOT EXISTS public.actors (\n",
    "    id          INTEGER PRIMARY KEY,                          \n",
    "    name        TEXT NOT NULL,\n",
    "    age         SMALLINT CHECK (age IS NULL OR (age BETWEEN 0 AND 150)),\n",
    "    gender      TEXT CHECK (gender IN ('Not set', 'Female', 'Male', 'Non-binary')),\n",
    "    popularity  REAL\n",
    ");\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS idx_actors_name_lower ON public.actors (lower(name));\n",
    "CREATE INDEX IF NOT EXISTS idx_actors_popularity ON public.actors (popularity);\n",
    "\n",
    "\n",
    "-- TABLE: genres\n",
    "CREATE TABLE IF NOT EXISTS public.genres (\n",
    "    id      INTEGER PRIMARY KEY,          -- TMDB genre id (manual)\n",
    "    name    TEXT NOT NULL UNIQUE\n",
    ");\n",
    "\n",
    "-- TABLE: movie_actors  (credits → cast, relación N:M)\n",
    "CREATE TABLE IF NOT EXISTS public.movie_actors (\n",
    "    movie_id INTEGER NOT NULL REFERENCES public.movies(id) ON DELETE CASCADE,\n",
    "    actor_id INTEGER NOT NULL REFERENCES public.actors(id) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (movie_id, actor_id)\n",
    ");\n",
    "\n",
    "-- TABLE: movie_genres  (genres, relación N:M)\n",
    "CREATE TABLE IF NOT EXISTS public.movie_genres (\n",
    "    movie_id INTEGER NOT NULL REFERENCES public.movies(id) ON DELETE CASCADE,\n",
    "    genre_id INTEGER NOT NULL REFERENCES public.genres(id) ON DELETE CASCADE,\n",
    "    PRIMARY KEY (movie_id, genre_id)\n",
    ");\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS idx_movie_actors_actor ON public.movie_actors (actor_id);\n",
    "CREATE INDEX IF NOT EXISTS idx_movie_genres_genre ON public.movie_genres (genre_id);\n",
    "```\n",
    "\n",
    ">**Nota:** Importante el orden de creación de las tablas, debido a la definción de sus relaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019fd0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "invocar_lambda(nombre_funcion=\"create_tables_tmdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86f5494",
   "metadata": {},
   "source": [
    "### RDS.3 Insertamos los datos guardados en S3\n",
    "\n",
    "DOCUMENTACION: **./lambdas/insert_data_tmdb**\n",
    "\n",
    "En S3 tenemos guardados:\n",
    "- **initial_load/movies/** Detalle de las peliculas\n",
    "- **initial_load/actors/** Detalle de los actores que trabajaron en esas peliculas (MUCHOS A MUCHOS)\n",
    "- **initial_load/genres/** Generos posibles de las peliculas (MUCHOS A MUCHOS)\n",
    "\n",
    "Por lo tanto debemos hacer una limpieza de datos guardados en S3, para insertarlos en nuestras tablas SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f010fda",
   "metadata": {},
   "source": [
    ">##### Funciones de limpieza S3 -> limpeza -> RDS (sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b2a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_with_median(df):\n",
    "    median = df[df[\"budget\"] != 0][\"budget\"].median()\n",
    "\n",
    "    df[\"budget\"] = [median if b == 0 else b for b in df[\"budget\"]]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_success_column(df):\n",
    "    df_original = df.copy()\n",
    "    if 'revenue' in df.columns and 'budget' in df.columns:\n",
    "        df[\"success\"] = (df_original[\"revenue\"] > df_original[\"budget\"]) & (df_original[\"vote_average\"] > 7)\n",
    "    else:\n",
    "        raise ValueError(\"El DataFrame debe contener las columnas 'revenue' y 'budget'\")\n",
    "    return df\n",
    "\n",
    "def prepare_movies_for_sql(df):\n",
    "    df_movies_original = df.copy()\n",
    "    df = df_movies_original[[\"id\", \"title\",\"popularity\", \"vote_average\", \"runtime\", \"budget\", \"revenue\", \"overview\", \"genres\", \"credits\", \"release_date\"]]\n",
    "    df[\"credits\"] = [get_values_for_row(credits[\"cast\"], \"id\") for credits in df_movies_original[\"credits\"]]\n",
    "    df[\"genres\"] = [get_values_for_row(genres, \"id\") for genres in df_movies_original[\"genres\"]]\n",
    "    df = add_success_column(df)\n",
    "    #df = impute_with_median(df)\n",
    "    return df\n",
    "\n",
    "def prepare_table_for_ia(df):\n",
    "    return  df[[\"popularity\",\"vote_average\",\"runtime\",\"budget\", \"succes\"]]\n",
    "\n",
    "# Para las columnas de CREDITS y GENRES donde nos vienen la información que relaciona la\n",
    "# tabla películas con actores y generos\n",
    "def get_values_for_row(items, column_name):\n",
    "    return [item.get(column_name) for item in items if isinstance(item, dict) and column_name in item]\n",
    "\n",
    "\n",
    "def get_actors_id_from_movies(df: pd.DataFrame, credits_col: str = \"credits\") -> list[int]:\n",
    "    # Concatenate all sub-lists, ignoring NaN\n",
    "    all_ids = []\n",
    "    for entry in df[credits_col]:\n",
    "        if isinstance(entry, list):\n",
    "            all_ids.extend(entry)\n",
    "\n",
    "    # Remove duplicates preserving order\n",
    "    seen = set()\n",
    "    unique_ids = []\n",
    "    for actor_id in all_ids:\n",
    "        if actor_id not in seen:\n",
    "            seen.add(actor_id)\n",
    "            unique_ids.append(actor_id)\n",
    "\n",
    "    return unique_ids\n",
    "\n",
    "\n",
    "def movie_genres_sql(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Construye la tabla relacional (movie_id, genre_id) \n",
    "    a partir de un DataFrame de películas con columna 'genres'.\n",
    "    \"\"\"\n",
    "    df_exploded = df[[\"id\", \"genres\"]].copy()\n",
    "    return (\n",
    "        df_exploded\n",
    "        .explode(\"genres\")\n",
    "        .dropna(subset=[\"genres\"])\n",
    "        .rename(columns={\"id\": \"movie_id\", \"genres\": \"genre_id\"})\n",
    "        .drop_duplicates(ignore_index=True)\n",
    "        .reset_index(drop=True)\n",
    "        .astype({\"movie_id\": \"int64\", \"genre_id\": \"int64\"})\n",
    "    )\n",
    "def movie_actors_sql(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build the relational table (movie_id, actor_id) from the movies DataFrame\n",
    "    where 'credits' is a list of actor IDs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame with columns ['movie_id', 'actor_id']\n",
    "    \"\"\"\n",
    "    df_exploded = df[[\"id\", \"credits\"]].copy()\n",
    "    return (\n",
    "        df_exploded\n",
    "        .explode(\"credits\")                          # cada actor en fila propia\n",
    "        .dropna(subset=[\"credits\"])                  # elimina None/NaN\n",
    "        .rename(columns={\"id\": \"movie_id\", \"credits\": \"actor_id\"})\n",
    "        .astype({\"movie_id\": \"int64\", \"actor_id\": \"int64\"})\n",
    "        .drop_duplicates(ignore_index=True)          # clave primaria (movie_id, actor_id)\n",
    "        .reset_index(drop=True)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9363e4",
   "metadata": {},
   "source": [
    "#### Funciones auxiliares\n",
    "\n",
    "Estas funcionaes nos transforman los data frames que hemos construido, en un insert con sus propios datos para la tabla en la base de datos RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "\n",
    "def df_to_movies_insert(df: pd.DataFrame, table: str = \"public.movies\") -> str:\n",
    "    required = [\n",
    "        \"id\", \"title\", \"popularity\", \"vote_average\", \"runtime\",\n",
    "        \"budget\", \"revenue\", \"overview\", \"release_date\", \"success\"\n",
    "    ]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required column(s): {missing}\")\n",
    "\n",
    "    def esc(s: str) -> str:\n",
    "        # Escape single quotes for SQL strings\n",
    "        return s.replace(\"'\", \"''\")\n",
    "\n",
    "    def fmt_str(s) -> str:\n",
    "        if pd.isna(s) or s is None:\n",
    "            return \"''\"\n",
    "        return f\"'{esc(str(s))}'\"\n",
    "\n",
    "    def fmt_int(x) -> str:\n",
    "        if pd.isna(x) or x is None:\n",
    "            return \"NULL\"\n",
    "        return str(int(x))\n",
    "\n",
    "    def fmt_dec(x, decimals: int) -> str:\n",
    "        # Use Decimal to avoid float artifacts and force fixed decimals\n",
    "        if pd.isna(x) or x is None:\n",
    "            return \"NULL\"\n",
    "        q = Decimal(\"1\").scaleb(-decimals)  # e.g., decimals=4 -> Decimal('0.0001')\n",
    "        val = Decimal(str(x)).quantize(q, rounding=ROUND_HALF_UP)\n",
    "        return f\"{val:.{decimals}f}\"\n",
    "\n",
    "    def fmt_date(d) -> str:\n",
    "        if pd.isna(d) or d is None:\n",
    "            return \"NULL\"\n",
    "        if isinstance(d, (datetime, date)):\n",
    "            return f\"DATE '{d.strftime('%Y-%m-%d')}'\"\n",
    "        s = str(d).strip()\n",
    "        if not s:\n",
    "            return \"NULL\"\n",
    "        try:\n",
    "            ymd = s[:10]\n",
    "            datetime.strptime(ymd, \"%Y-%m-%d\")\n",
    "            return f\"DATE '{ymd}'\"\n",
    "        except Exception:\n",
    "            return \"NULL\"\n",
    "\n",
    "    def fmt_bool(b) -> str:\n",
    "        if pd.isna(b) or b is None:\n",
    "            return \"FALSE\"\n",
    "        return \"TRUE\" if bool(b) else \"FALSE\"\n",
    "\n",
    "    values = []\n",
    "    for _, r in df.iterrows():\n",
    "        row_sql = (\n",
    "            fmt_int(r[\"id\"]),                    # id\n",
    "            fmt_str(r[\"title\"]),                 # title\n",
    "            fmt_dec(r[\"popularity\"], 4),         # popularity\n",
    "            fmt_dec(r[\"vote_average\"], 1),       # vote_average\n",
    "            fmt_int(r[\"runtime\"]),               # runtime\n",
    "            fmt_int(r[\"budget\"]),                # budget\n",
    "            fmt_int(r[\"revenue\"]),               # revenue\n",
    "            fmt_str(r[\"overview\"] if \"overview\" in r else \"\"),  # overview\n",
    "            fmt_date(r[\"release_date\"]),         # release_date\n",
    "            fmt_bool(r[\"success\"])               # success\n",
    "        )\n",
    "        values.append(f\"({', '.join(row_sql)})\")\n",
    "\n",
    "    if not values:\n",
    "        raise ValueError(\"DataFrame is empty; no rows to insert.\")\n",
    "\n",
    "    head = (\n",
    "        f\"INSERT INTO {table} (\\n\"\n",
    "        f\"  id, title, popularity, vote_average, runtime, budget, revenue, overview, release_date, success\\n\"\n",
    "        f\") VALUES\\n\"\n",
    "    )\n",
    "    tail = \"\\nON CONFLICT (id) DO NOTHING;\"\n",
    "    return head + \",\\n\".join(values) + tail\n",
    "\n",
    "def df_to_movie_genres_insert(df: pd.DataFrame, table: str = \"public.movie_genres\") -> str:\n",
    "    # Validate columns\n",
    "    required = {\"movie_id\", \"genre_id\"}\n",
    "    if not required.issubset(df.columns):\n",
    "        raise ValueError(f\"DataFrame must contain columns: {sorted(required)}\")\n",
    "\n",
    "    # Remove rows with nulls and exact duplicates (sane pre-checks for PK (movie_id, genre_id))\n",
    "    df_clean = (\n",
    "        df.loc[:, [\"movie_id\", \"genre_id\"]]\n",
    "          .dropna(subset=[\"movie_id\", \"genre_id\"])\n",
    "          .drop_duplicates(ignore_index=True)\n",
    "    )\n",
    "\n",
    "    if df_clean.empty:\n",
    "        raise ValueError(\"DataFrame is empty after cleaning; no rows to insert.\")\n",
    "\n",
    "    # Build VALUES tuples\n",
    "    values = []\n",
    "    for _, r in df_clean.iterrows():\n",
    "        try:\n",
    "            movie_id = int(r[\"movie_id\"])\n",
    "            genre_id = int(r[\"genre_id\"])\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Non-integer IDs found in row: {r.to_dict()}\")\n",
    "        values.append(f\"({movie_id}, {genre_id})\")\n",
    "\n",
    "    head = (\n",
    "        f\"INSERT INTO {table} (\\n\"\n",
    "        f\"  movie_id, genre_id\\n\"\n",
    "        f\") VALUES\\n\"\n",
    "    )\n",
    "    tail = \"\\nON CONFLICT DO NOTHING;\"\n",
    "\n",
    "    return head + \",\\n\".join(values) + tail\n",
    "\n",
    "def df_to_actors_insert(\n",
    "    df: pd.DataFrame,\n",
    "    table: str = \"public.actors\",\n",
    "    validate_gender: bool = True,\n",
    ") -> str:\n",
    "    required = {\"id\", \"name\", \"age\", \"gender\", \"popularity\"}\n",
    "    if not required.issubset(df.columns):\n",
    "        raise ValueError(f\"DataFrame must contain columns: {sorted(required)}\")\n",
    "\n",
    "    allowed_genders = {\"Not set\", \"Female\", \"Male\", \"Non-binary\"}\n",
    "\n",
    "    def esc(s: str) -> str:\n",
    "        return s.replace(\"'\", \"''\")\n",
    "\n",
    "    def fmt_str(s) -> str:\n",
    "        if pd.isna(s) or s is None:\n",
    "            return \"''\"\n",
    "        return f\"'{esc(str(s))}'\"\n",
    "\n",
    "    def fmt_int(x) -> str:\n",
    "        if pd.isna(x) or x is None:\n",
    "            return \"NULL\"\n",
    "        return str(int(x))\n",
    "\n",
    "    def fmt_float(x, decimals: int = 4) -> str:\n",
    "        if pd.isna(x) or x is None:\n",
    "            return \"NULL\"\n",
    "        return f\"{float(x):.{decimals}f}\"\n",
    "\n",
    "    def fmt_gender(g) -> str:\n",
    "        if pd.isna(g) or g is None:\n",
    "            # si falta, lo tratamos como 'Not set'\n",
    "            g = \"Not set\"\n",
    "        g_str = str(g)\n",
    "        if validate_gender and g_str not in allowed_genders:\n",
    "            raise ValueError(\n",
    "                f\"Invalid gender value '{g_str}'. Expected one of {sorted(allowed_genders)}.\"\n",
    "            )\n",
    "        return f\"'{esc(g_str)}'\"\n",
    "\n",
    "    values = []\n",
    "    for _, r in df.iterrows():\n",
    "        tup = (\n",
    "            fmt_int(r[\"id\"]),            # id\n",
    "            fmt_str(r[\"name\"]),          # name\n",
    "            fmt_int(r[\"age\"]),           # age -> NULL si None/NaN\n",
    "            fmt_gender(r[\"gender\"]),     # gender como TEXT validado\n",
    "            fmt_float(r[\"popularity\"], 4)# popularity\n",
    "        )\n",
    "        values.append(f\"({', '.join(tup)})\")\n",
    "\n",
    "    if not values:\n",
    "        raise ValueError(\"DataFrame is empty; no rows to insert.\")\n",
    "\n",
    "    head = (\n",
    "        f\"INSERT INTO {table} (\\n\"\n",
    "        f\"  id, name, age, gender, popularity\\n\"\n",
    "        f\") VALUES\\n\"\n",
    "    )\n",
    "    tail = \"\\nON CONFLICT (id) DO NOTHING;\"\n",
    "\n",
    "    return head + \",\\n\".join(values) + tail\n",
    "\n",
    "def df_to_movie_actors_insert(df: pd.DataFrame, table: str = \"public.movie_actors\") -> str:\n",
    "    \"\"\"\n",
    "    Build a single SQL INSERT statement for the `public.movie_actors` table\n",
    "    from a pandas DataFrame that already mirrors the table schema.\n",
    "\n",
    "    Expected DataFrame columns (exact):\n",
    "      - movie_id (int, NOT NULL)\n",
    "      - actor_id (int, NOT NULL)\n",
    "\n",
    "    Behavior:\n",
    "      - Generates: INSERT INTO <table> (movie_id, actor_id) VALUES (...), (...), ... ON CONFLICT DO NOTHING;\n",
    "      - Drops duplicate pairs within the DataFrame to avoid redundant values.\n",
    "      - Raises if DataFrame is empty or columns are missing.\n",
    "    \"\"\"\n",
    "    required = {\"movie_id\", \"actor_id\"}\n",
    "    if not required.issubset(df.columns):\n",
    "        raise ValueError(f\"DataFrame must contain columns: {sorted(required)}\")\n",
    "\n",
    "    # Clean duplicates and NaNs\n",
    "    df_clean = (\n",
    "        df.loc[:, [\"movie_id\", \"actor_id\"]]\n",
    "          .dropna(subset=[\"movie_id\", \"actor_id\"])\n",
    "          .drop_duplicates(ignore_index=True)\n",
    "    )\n",
    "\n",
    "    if df_clean.empty:\n",
    "        raise ValueError(\"DataFrame is empty after cleaning; no rows to insert.\")\n",
    "\n",
    "    values = []\n",
    "    for _, r in df_clean.iterrows():\n",
    "        movie_id = int(r[\"movie_id\"])\n",
    "        actor_id = int(r[\"actor_id\"])\n",
    "        values.append(f\"({movie_id}, {actor_id})\")\n",
    "\n",
    "    head = (\n",
    "        f\"INSERT INTO {table} (\\n\"\n",
    "        f\"  movie_id, actor_id\\n\"\n",
    "        f\") VALUES\\n\"\n",
    "    )\n",
    "    tail = \"\\nON CONFLICT DO NOTHING;\"\n",
    "\n",
    "    return head + \",\\n\".join(values) + tail\n",
    "\n",
    "def df_to_genres_insert(df: pd.DataFrame, table: str = \"public.genres\") -> str:\n",
    "    \"\"\"\n",
    "    Build a single SQL INSERT statement for the `public.genres` table\n",
    "    from a pandas DataFrame that already mirrors the table schema.\n",
    "\n",
    "    Expected DataFrame columns:\n",
    "      - id (int, PK)\n",
    "      - name (str, NOT NULL)\n",
    "\n",
    "    Behavior:\n",
    "      - Escapa comillas simples en name.\n",
    "      - NaN/None en name -> '' (vacío).\n",
    "      - Devuelve un INSERT con ON CONFLICT (id) DO NOTHING.\n",
    "    \"\"\"\n",
    "    required = {\"id\", \"name\"}\n",
    "    if not required.issubset(df.columns):\n",
    "        raise ValueError(f\"DataFrame must contain columns: {sorted(required)}\")\n",
    "\n",
    "    def esc(s: str) -> str:\n",
    "        return s.replace(\"'\", \"''\")\n",
    "\n",
    "    def fmt_str(s) -> str:\n",
    "        if pd.isna(s) or s is None:\n",
    "            return \"''\"\n",
    "        return f\"'{esc(str(s))}'\"\n",
    "\n",
    "    def fmt_int(x) -> str:\n",
    "        if pd.isna(x) or x is None:\n",
    "            return \"NULL\"\n",
    "        return str(int(x))\n",
    "\n",
    "    values = []\n",
    "    for _, r in df.iterrows():\n",
    "        tup = (\n",
    "            fmt_int(r[\"id\"]),       # id\n",
    "            fmt_str(r[\"name\"]),     # name\n",
    "        )\n",
    "        values.append(f\"({', '.join(tup)})\")\n",
    "\n",
    "    if not values:\n",
    "        raise ValueError(\"DataFrame is empty; no rows to insert.\")\n",
    "\n",
    "    head = f\"INSERT INTO {table} (\\n  id, name\\n) VALUES\\n\"\n",
    "    tail = \"\\nON CONFLICT (id) DO NOTHING;\"\n",
    "\n",
    "    return head + \",\\n\".join(values) + tail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f314afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = prepare_movies_for_sql(df_movies_sucia)\n",
    "df_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f9e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_ids = get_actors_id_from_movies(df_movies)\n",
    "actors_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b3714",
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_details = fetch_details_for_ids(actors_ids, \"person\")\n",
    "actors_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "\n",
    "def compute_actor_age(birthday: str | None, deathday: str | None) -> int | None:\n",
    "    if not birthday or pd.isna(birthday) or birthday == \"None\":\n",
    "        return None   # no se conoce la edad\n",
    "\n",
    "    try:\n",
    "        birth_date = datetime.strptime(str(birthday)[:10], \"%Y-%m-%d\").date()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    if deathday and deathday != \"None\" and not pd.isna(deathday):\n",
    "        try:\n",
    "            end_date = datetime.strptime(str(deathday)[:10], \"%Y-%m-%d\").date()\n",
    "        except Exception:\n",
    "            end_date = date.today()\n",
    "    else:\n",
    "        end_date = date.today()\n",
    "\n",
    "    age = end_date.year - birth_date.year - (\n",
    "        (end_date.month, end_date.day) < (birth_date.month, birth_date.day)\n",
    "    )\n",
    "\n",
    "    return age if age >= 0 else None\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def map_actor_gender(df: pd.DataFrame, gender_col: str = \"gender\") -> pd.DataFrame:\n",
    "    \n",
    "    mapping = {\n",
    "        0: \"Not set\",\n",
    "        1: \"Female\",\n",
    "        2: \"Male\",\n",
    "        3: \"Non-binary\"\n",
    "    }\n",
    "    df = df.copy()\n",
    "    df[gender_col] = df[gender_col].replace(mapping)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37fc4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_actors(df: pd.DataFrame):\n",
    "    toret = df[[\"id\",\"name\",  \"birthday\", \"deathday\", \"gender\", \"popularity\"]]\n",
    "    toret[\"age\"] = df.apply(\n",
    "        lambda r: compute_actor_age(r[\"birthday\"], r[\"deathday\"]),\n",
    "        axis=1\n",
    "    )\n",
    "    toret = toret.drop(columns=[\"birthday\", \"deathday\"])\n",
    "    toret = map_actor_gender(toret)\n",
    "    return toret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec0ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actors = pd.DataFrame(actors_details)\n",
    "df_actors = clean_actors(df_actors)\n",
    "df_actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_insert = df_to_actors_insert(df_actors)\n",
    "actors_insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b8a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "invocar_lambda(\"insert_data_tmdb\", {\"QUERY\": actors_insert})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a988c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_insert = df_to_movies_insert(df_movies)\n",
    "movies_insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfc2671",
   "metadata": {},
   "outputs": [],
   "source": [
    "invocar_lambda(\"insert_data_tmdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95373875",
   "metadata": {},
   "outputs": [],
   "source": [
    "invocar_lambda(\"insert_data_tmdb\", {\n",
    "    \"QUERY\": movies_insert\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a769b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie_genres = movie_genres_sql(df_movies)\n",
    "df_movie_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a8b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_movie_genres = df_to_movie_genres_insert(df_movie_genres)\n",
    "insert_movie_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d8e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "invocar_lambda(\"insert_data_tmdb\", {\n",
    "    \"QUERY\": insert_movie_genres\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913f112b",
   "metadata": {},
   "source": [
    "## EC2 - Con Fast api\n",
    "\n",
    "Nos hemos construido una instancia ec2 que utilizaremos como servidor, que corra nuestro codigo python y escuche peticiones a los endpoints.\n",
    "\n",
    "Para ver la documentación en profundidad de la API:\n",
    "- **https://ec2-34-244-17-61.eu-west-1.compute.amazonaws.com:8000/docs**\n",
    "\n",
    "\n",
    "![Alt](./img/ec2.png \"Propiedades del EC2\")\n",
    "\n",
    "- ### /predict:\n",
    "    - Con la IA clasificadora que hemos entrenado espera datos de pelicula para predecir si tendrán exito. Nos devuelve una lista que representa la columna a predecir de los datos enviados. Ec2 necesita el fichero del modelo compilado para esto\n",
    "\n",
    "- ### /ask-text\n",
    "    - Paso 1: Le pasamos una pregunta en lenguaje natural como parámetro, con la libreria __google-genai__ usamos gemini para generarnos una sentencia SQL a partir de la pregunta\n",
    "    - Paso 2: Ejecutaremos con la lambda __send_quey__ que se conectará con __pycopg2__ a nuestra rds devolviendo la informacion de la sentencia.\n",
    "    - Paso 3: Le pasamos a gemini otra vez la información de la ejecucion de la query, para que transforme los datos a una explicación en lenguaje natural.\n",
    "\n",
    "- ### /ask-visual\n",
    "    - Paso 1: Mismo que en **/ask_text** pero tiene un parametro extra \"format\" que indica como queremos ver el resultado:\n",
    "        * **format = \"code\"**: el endooint entiende que estamos realizando la request desde código y nos devuelve codigo python para ejecutar y ver las graficas.\n",
    "        * **format = html**: pensado para cunado hacemos la peticion a través del navegador, mostrando la grafica en el propio navegador en codigo html\n",
    "    - Paso 2: Mismo que en **/ask_text**\n",
    "    - Paso 3: Se le pide por ultimo a gemini otra vez que desde los datos mostrados por la query en nuestro RDS. Generara codigo python que guardará en un archivo, si format = code este codigo será el resultado del endpoint, pero si format = html, este codigo guardado en un archivo temporal en ec2 será ejecutado, y generará una imagen que con una funcion envoltorio prepararemos y mostraremos con html\n",
    "\n",
    ">NOTA: Para ver en profundid el codigo de la nuestra api revisar la carpeta fast_api, esa carpeta se sube a ec2 con el comando \n",
    "```bash\n",
    "# Subir carpeta local 'mi_carpeta' a /home/ec2-user/ en la instancia\n",
    "scp -i /ruta/a/tu/key.pem -r ./mi_carpeta ec2-user@EC2_PUBLIC_IP:/home/ec2-user/\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f122e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01575d2f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
