{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d7189df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import random\n",
    "import datetime\n",
    "from datetime import timedelta, date\n",
    "from typing import List, Dict, Any, Optional\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from itertools import chain\n",
    "\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe07bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = \"eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiI2MDkxNGNiOTI5OTI2OGM1ZWQ2NjcxN2UyYmM5MzkyNyIsIm5iZiI6MTc1Njk3NTgxMS41NzMsInN1YiI6IjY4Yjk1MmMzNDYwNDI1OGMwNThjZGM1ZiIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.T-AD7PBLVI5hKAyYiHrheP1xhlGpIBZxJVJq_WlzsGM\"\n",
    "BASE = \"https://api.themoviedb.org/3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15c9fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ACCESS_TOKEN = \"eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiI2MDkxNGNiOTI5OTI2OGM1ZWQ2NjcxN2UyYmM5MzkyNyIsIm5iZiI6MTc1Njk3NTgxMS41NzMsInN1YiI6IjY4Yjk1MmMzNDYwNDI1OGMwNThjZGM1ZiIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.T-AD7PBLVI5hKAyYiHrheP1xhlGpIBZxJVJq_WlzsGM\"\n",
    "BASE = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "# Requisitos (layer/build): requests, boto3, pandas, pyarrow, urllib3\n",
    "\n",
    "import os, io, json\n",
    "from datetime import date, datetime, timedelta\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import boto3\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "BUKECT= \"dai03rt-proyecto\"\n",
    "\n",
    "# ======= ENV =======\n",
    "#ACCESS_TOKEN = os.environ[\"ACCESS_TOKEN\"]      # TMDB Bearer\n",
    "#BASE         = os.environ[\"BASE\"]              # https://api.themoviedb.org/3\n",
    "#BUCKET       = os.environ[\"BUCKET\"]\n",
    "PREFIX       = os.environ.get(\"PREFIX\", \"initial_load\")  # carpeta raíz en S3\n",
    "REGION       = os.environ.get(\"REGION\", \"eu-west-1\")\n",
    "\n",
    "# Tuning\n",
    "MAX_WORKERS    = int(os.environ.get(\"MAX_WORKERS\", \"12\"))     # paralelismo para details\n",
    "DETAIL_BATCH   = int(os.environ.get(\"DETAIL_BATCH\", \"50\"))    # ids por oleada\n",
    "TIME_GUARD_MS  = int(os.environ.get(\"TIME_GUARD_MS\", \"6000\")) # margen para cortar y re-invocar\n",
    "\n",
    "s3 = boto3.client(\"s3\", region_name=REGION)\n",
    "lambda_client = boto3.client(\"lambda\", region_name=REGION)\n",
    "\n",
    "# ------- HTTP session con backoff -------\n",
    "def _make_session() -> requests.Session:\n",
    "    s = requests.Session()\n",
    "    s.headers.update({\"accept\": \"application/json\", \"Authorization\": f\"Bearer {ACCESS_TOKEN}\"})\n",
    "    retry = Retry(\n",
    "        total=6, connect=3, read=3, backoff_factor=0.6,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\"], raise_on_status=False,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry, pool_connections=100, pool_maxsize=100)\n",
    "    s.mount(\"https://\", adapter); s.mount(\"http://\", adapter)\n",
    "    return s\n",
    "\n",
    "# ------- Discover (una página) -------\n",
    "def _discover_page(session: requests.Session, page: int, gte: date, lte: date) -> Tuple[int, List[int]]:\n",
    "    url = f\"{BASE}/discover/movie\"\n",
    "    params = {\n",
    "        \"language\": \"es-ES\",\n",
    "        \"include_adult\": \"false\",\n",
    "        \"include_video\": \"false\",\n",
    "        \"primary_release_date.gte\": gte.strftime(\"%Y-%m-%d\"),\n",
    "        \"primary_release_date.lte\": lte.strftime(\"%Y-%m-%d\"),\n",
    "        \"page\": page,\n",
    "    }\n",
    "    r = session.get(url, params=params, timeout=30); r.raise_for_status()\n",
    "    d = r.json()\n",
    "    total_pages = int(d.get(\"total_pages\", 0))\n",
    "    ids = [m[\"id\"] for m in d.get(\"results\", [])]\n",
    "    return total_pages, ids\n",
    "\n",
    "# ------- Details de película -------\n",
    "def _movie_detail(session: requests.Session, mid: int) -> Dict[str, Any]:\n",
    "    url = f\"{BASE}/movie/{mid}\"\n",
    "    # Si necesitas más info, añade append_to_response p.ej. release_dates,videos,keywords\n",
    "    r = session.get(url, timeout=30)\n",
    "    if r.status_code == 404:\n",
    "        return {\"id\": mid, \"_missing\": True}\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "# ------- Utilidades -------\n",
    "def _chunks(seq: List[int], size: int):\n",
    "    for i in range(0, len(seq), size):\n",
    "        yield seq[i:i+size]\n",
    "\n",
    "def _save_parquet(records: List[Dict[str, Any]], ventana_idx: int, part_index: int) -> str:\n",
    "    \"\"\"Guarda un part de una ventana: initial_load/ventana_<idx>/<part>_movies.parquet\"\"\"\n",
    "    if not records:\n",
    "        return \"\"\n",
    "    table = pa.Table.from_pylist(records)\n",
    "    buf = io.BytesIO()\n",
    "    pq.write_table(table, buf, compression=\"snappy\")\n",
    "    buf.seek(0)\n",
    "    key = f\"{PREFIX.rstrip('/')}/ventana_{ventana_idx}/{part_index}_movies.parquet\"\n",
    "    s3.put_object(Bucket=BUCKET, Key=key, Body=buf.getvalue(), ContentType=\"application/octet-stream\")\n",
    "    return key\n",
    "\n",
    "def _reinvoke_self(payload: Dict[str, Any]) -> None:\n",
    "    lambda_client.invoke(\n",
    "        FunctionName=os.environ[\"AWS_LAMBDA_FUNCTION_NAME\"],\n",
    "        InvocationType=\"Event\",  # async\n",
    "        Payload=json.dumps(payload).encode(\"utf-8\"),\n",
    "    )\n",
    "\n",
    "def _generate_windows(range_from: date, range_to: date, step_days: int):\n",
    "    \"\"\"Divide [range_from..range_to] en sub-ventanas de 'step_days' (inclusive).\"\"\"\n",
    "    idx = 1\n",
    "    cur = range_from\n",
    "    while cur <= range_to:\n",
    "        win_to = min(cur + timedelta(days=step_days-1), range_to)\n",
    "        yield (idx, cur, win_to)\n",
    "        idx += 1\n",
    "        cur = win_to + timedelta(days=1)\n",
    "\n",
    "# ------- Handler -------\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"\n",
    "    event:\n",
    "    {\n",
    "      \"from\": \"YYYY-MM-DD\",\n",
    "      \"to\":   \"YYYY-MM-DD\",\n",
    "      \"step_days\": 180,\n",
    "\n",
    "      # Para continuar una ventana ya empezada:\n",
    "      # \"resume\": { \"ventana_idx\": 3, \"win_from\": \"YYYY-MM-DD\", \"win_to\": \"YYYY-MM-DD\", \"next_page\": 1, \"part_index\": 1 }\n",
    "    }\n",
    "    \"\"\"\n",
    "    range_from = date.fromisoformat(event[\"from\"])\n",
    "    range_to   = date.fromisoformat(event[\"to\"])\n",
    "    step_days  = int(event.get(\"step_days\", 180))\n",
    "\n",
    "    # Si viene \"resume\", procesamos directamente esa ventana/página/parte\n",
    "    resume = event.get(\"resume\")\n",
    "\n",
    "    with _make_session() as session:\n",
    "        if resume:\n",
    "            _process_window(session, context,\n",
    "                            ventana_idx=int(resume[\"ventana_idx\"]),\n",
    "                            win_from=date.fromisoformat(resume[\"win_from\"]),\n",
    "                            win_to=date.fromisoformat(resume[\"win_to\"]),\n",
    "                            next_page=int(resume.get(\"next_page\", 1)),\n",
    "                            part_index=int(resume.get(\"part_index\", 1)))\n",
    "            return {\"ok\": True, \"msg\": \"resumed window processed\"}\n",
    "\n",
    "        # Modo normal: iterar todas las ventanas del rango\n",
    "        for ventana_idx, win_from, win_to in _generate_windows(range_from, range_to, step_days):\n",
    "            cont = _process_window(session, context,\n",
    "                                   ventana_idx=ventana_idx, win_from=win_from, win_to=win_to,\n",
    "                                   next_page=1, part_index=1)\n",
    "            # Si cont==True, la propia lambda ya se re-invocó con resume y termina aquí\n",
    "            if cont:\n",
    "                return {\"ok\": True, \"msg\": f\"timeboxed; auto-resume scheduled for ventana_{ventana_idx}\"}\n",
    "\n",
    "    return {\"ok\": True, \"msg\": \"all windows completed\"}\n",
    "\n",
    "# ------- Core por ventana -------\n",
    "def _process_window(session, context, *, ventana_idx: int, win_from: date, win_to: date,\n",
    "                    next_page: int, part_index: int) -> bool:\n",
    "    \"\"\"\n",
    "    Devuelve True si se quedó sin tiempo y programó auto-reinvocación (resume). False si la ventana se completó.\n",
    "    \"\"\"\n",
    "    details_buffer: List[Dict[str, Any]] = []\n",
    "\n",
    "    def time_left_ms():\n",
    "        return context.get_remaining_time_in_millis()\n",
    "\n",
    "    # Primera página para saber total_pages (cap 500)\n",
    "    total_pages, ids = _discover_page(session, next_page, win_from, win_to)\n",
    "    total_pages = min(total_pages, 500)\n",
    "\n",
    "    page = next_page\n",
    "    while page <= total_pages:\n",
    "        if page != next_page:\n",
    "            _, ids = _discover_page(session, page, win_from, win_to)\n",
    "\n",
    "        # Details por lotes y en paralelo controlado\n",
    "        for group in _chunks(ids, DETAIL_BATCH):\n",
    "            if time_left_ms() < TIME_GUARD_MS:\n",
    "                # flush parcial y re-invocar con checkpoint\n",
    "                if details_buffer:\n",
    "                    _save_parquet(details_buffer, ventana_idx, part_index); part_index += 1; details_buffer.clear()\n",
    "                _reinvoke_self({\n",
    "                    \"from\": win_from.isoformat(), \"to\": win_to.isoformat(), \"step_days\": (win_to - win_from).days + 1,\n",
    "                    \"resume\": {\n",
    "                        \"ventana_idx\": ventana_idx,\n",
    "                        \"win_from\": win_from.isoformat(),\n",
    "                        \"win_to\": win_to.isoformat(),\n",
    "                        \"next_page\": page,\n",
    "                        \"part_index\": part_index\n",
    "                    }\n",
    "                })\n",
    "                return True\n",
    "\n",
    "            results = []\n",
    "            with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "                futs = {ex.submit(_movie_detail, session, mid): mid for mid in group}\n",
    "                for fut in as_completed(futs):\n",
    "                    try:\n",
    "                        results.append(fut.result())\n",
    "                    except Exception as e:\n",
    "                        results.append({\"id\": futs[fut], \"_error\": True, \"exception\": str(e)})\n",
    "            details_buffer.extend(results)\n",
    "\n",
    "        # Flush de seguridad por tamaño o por tiempo\n",
    "        if len(details_buffer) >= 5000 or time_left_ms() < TIME_GUARD_MS:\n",
    "            _save_parquet(details_buffer, ventana_idx, part_index); part_index += 1; details_buffer.clear()\n",
    "            if time_left_ms() < TIME_GUARD_MS:\n",
    "                _reinvoke_self({\n",
    "                    \"from\": win_from.isoformat(), \"to\": win_to.isoformat(), \"step_days\": (win_to - win_from).days + 1,\n",
    "                    \"resume\": {\n",
    "                        \"ventana_idx\": ventana_idx,\n",
    "                        \"win_from\": win_from.isoformat(),\n",
    "                        \"win_to\": win_to.isoformat(),\n",
    "                        \"next_page\": page + 1,\n",
    "                        \"part_index\": part_index\n",
    "                    }\n",
    "                })\n",
    "                return True\n",
    "\n",
    "        page += 1\n",
    "\n",
    "    # Ventana completada: guarda lo que quede y listo\n",
    "    if details_buffer:\n",
    "        _save_parquet(details_buffer, ventana_idx, part_index); details_buffer.clear()\n",
    "    print(f\"[OK] ventana_{ventana_idx} {win_from}..{win_to} completada\")\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caaf623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "BUKECT_NAME = \"dai03rt-proyecto\"\n",
    "ACCESS_KEY_ID = \"AKIAWZEDMKF3SHFDRH3B\"\n",
    "SECRET_KEY = \"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\"\n",
    "REGION = \"eu-west-1\"\n",
    "\n",
    "GENRES_KEY = \"initial_load/genres/genres.parquet\"\n",
    "\n",
    "s3 = boto3.client(\"s3\",aws_access_key_id = ACCESS_KEY_ID,aws_secret_access_key = SECRET_KEY,region_name=REGION) \n",
    "\n",
    "lambda_ = boto3.client(\"lambda\",\n",
    "                  aws_access_key_id = ACCESS_KEY_ID,\n",
    "                  aws_secret_access_key = SECRET_KEY,\n",
    "                  region_name=REGION) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f5f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Notebook test cell: invocar tu Lambda y comprobar outputs en S3 ---\n",
    "\n",
    "import json\n",
    "from datetime import date\n",
    "import boto3\n",
    "\n",
    "\n",
    "lambda_client = boto3.client(\"lambda\", region_name=REGION)\n",
    "s3 = boto3.client(\"s3\", region_name=REGION)\n",
    "\n",
    "def invoke_lambda(payload: dict, async_: bool = False):\n",
    "    \"\"\"Invoca la lambda con el payload dado (sync por defecto).\"\"\"\n",
    "    resp = lambda_client.invoke(\n",
    "        FunctionName=\"funcion_inicial\",\n",
    "        InvocationType=\"Event\" if async_ else \"RequestResponse\",\n",
    "        Payload=json.dumps(payload).encode(\"utf-8\"),\n",
    "    )\n",
    "    if async_:\n",
    "        print(\"✔ Invocación async enviada.\")\n",
    "        return None\n",
    "    print(\"HTTP Status:\", resp.get(\"StatusCode\"))\n",
    "    body = resp.get(\"Payload\").read().decode(\"utf-8\")\n",
    "    try:\n",
    "        print(\"Respuesta Lambda:\", json.loads(body))\n",
    "    except Exception:\n",
    "        print(\"Respuesta Lambda (raw):\", body)\n",
    "\n",
    "\n",
    "# 🧪 Smoke test: rango pequeño para validar el flujo end-to-end\n",
    "payload = {\n",
    "    \"from\": \"2019-01-01\",\n",
    "    \"to\":   \"2019-01-07\",\n",
    "    \"step_days\": 3\n",
    "}\n",
    "invoke_lambda(payload, async_=False)\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# (Opcional) Helpers por si quieres fan-out por ventanas desde el notebook\n",
    "# en vez de que la lambda itere internamente:\n",
    "#\n",
    "# from datetime import timedelta\n",
    "# def generate_windows():\n",
    "#     rangos_step = [\n",
    "#         (date(2005, 1, 1),  date(2010, 12, 31), 182),\n",
    "#         (date(2011, 1, 1),  date(2013, 9, 16),  120),\n",
    "#         (date(2013, 9, 17), date(2014, 1, 6),   100),\n",
    "#         (date(2014, 1, 7),  date(2015, 12, 31), 110),\n",
    "#         (date(2016, 1, 1),  date(2021, 12, 31), 70),\n",
    "#         (date(2022, 1, 1),  date(2024, 10, 16), 60),\n",
    "#         (date(2024, 10, 17),date(2024, 12, 16), 30),\n",
    "#         (date(2024, 12, 17),date.today(),       60),\n",
    "#     ]\n",
    "#     windows = []\n",
    "#     widx = 1\n",
    "#     for start, end, step in rangos_step:\n",
    "#         cur = start\n",
    "#         from datetime import timedelta\n",
    "#         while cur <= end:\n",
    "#             win_end = min(cur + timedelta(days=step) - timedelta(days=1), end)\n",
    "#             windows.append((widx, cur, win_end))\n",
    "#             widx += 1\n",
    "#             cur = win_end + timedelta(days=1)\n",
    "#     return windows\n",
    "#\n",
    "# # Fan-out asíncrono de todas las ventanas:\n",
    "# for idx, start, end in generate_windows():\n",
    "#     invoke_lambda({\"from\": start.isoformat(), \"to\": end.isoformat(), \"step_days\": (end-start).days+1}, async_=True)\n",
    "# print(\"✔ Ventanas encoladas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9415a8",
   "metadata": {},
   "source": [
    "# LAMBDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49426f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listar_funciones():\n",
    "    response = lambda_.list_functions()\n",
    "    for f in response['Functions']:\n",
    "        print(f\"{f['FunctionName']} | Runtime: {f['Runtime']} | Última modif: {f['LastModified']}\")\n",
    "        \n",
    "def invocar_lambda(nombre_funcion, payload={}):\n",
    "    try:\n",
    "        response = lambda_.invoke(\n",
    "            FunctionName=nombre_funcion,\n",
    "            InvocationType='RequestResponse',\n",
    "            Payload=json.dumps(payload),\n",
    "        )\n",
    "        print(\"Respuesta:\")\n",
    "        result_raw = (response['Payload']).read().decode('utf-8')\n",
    "        result = json.loads(result_raw)\n",
    "        print(result)\n",
    "        return result\n",
    "    except ClientError as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfffe735",
   "metadata": {},
   "source": [
    "# S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06cda21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Listar funciones Lambda existentes\n",
    "\n",
    "# Listar objetos del bucket\n",
    "def list_obj_s3():\n",
    "    response = s3.list_objects_v2(Bucket=BUKECT_NAME)\n",
    "    \n",
    "    if 'Contents' in response:\n",
    "        for obj in response['Contents']:\n",
    "            print(obj['Key'], obj['Size'], \"bytes\")\n",
    "    else:\n",
    "        print(\"No hay objetos en el bucket.\")\n",
    "        \n",
    "def save_data_s3(\n",
    "    records: List[Dict[str, Any]],\n",
    "    *,\n",
    "    key: str,\n",
    "    compression: str = \"snappy\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Guarda una lista de diccionarios como Parquet en S3.\n",
    "    \"\"\"\n",
    "    # Convierte lista de dicts -> Arrow Table (sin validar nada)\n",
    "    table = pa.Table.from_pylist(records)\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    pq.write_table(table, buf, compression=compression)\n",
    "    buf.seek(0)\n",
    "\n",
    "    s3.put_object(Bucket=BUKECT_NAME, Key=key, Body=buf.getvalue(), ContentType=\"application/octet-stream\")\n",
    "    return f\"Subido correctamente a s3://{BUKECT_NAME}/{key}\"\n",
    "\n",
    "\n",
    "def load_data_s3(key: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Lee un Parquet desde S3 y lo devuelve como lista de diccionarios.\n",
    "    \"\"\"\n",
    "    obj = s3.get_object(Bucket=BUKECT_NAME, Key=key)\n",
    "    body = obj[\"Body\"].read()\n",
    "    table = pq.read_table(io.BytesIO(body))\n",
    "    # A lista de dicts; usa pandas por simplicidad\n",
    "    return table.to_pandas().to_dict(orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74c77553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 28, 'name': 'Action'},\n",
       " {'id': 12, 'name': 'Adventure'},\n",
       " {'id': 16, 'name': 'Animation'},\n",
       " {'id': 35, 'name': 'Comedy'},\n",
       " {'id': 80, 'name': 'Crime'},\n",
       " {'id': 99, 'name': 'Documentary'},\n",
       " {'id': 18, 'name': 'Drama'},\n",
       " {'id': 10751, 'name': 'Family'},\n",
       " {'id': 14, 'name': 'Fantasy'},\n",
       " {'id': 36, 'name': 'History'},\n",
       " {'id': 27, 'name': 'Horror'},\n",
       " {'id': 10402, 'name': 'Music'},\n",
       " {'id': 9648, 'name': 'Mystery'},\n",
       " {'id': 10749, 'name': 'Romance'},\n",
       " {'id': 878, 'name': 'Science Fiction'},\n",
       " {'id': 10770, 'name': 'TV Movie'},\n",
       " {'id': 53, 'name': 'Thriller'},\n",
       " {'id': 10752, 'name': 'War'},\n",
       " {'id': 37, 'name': 'Western'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_genres = fetch_tmdb_movie_genres()\n",
    "movie_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e03aaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_load/ 0 bytes\n",
      "initial_load/movies/ 0 bytes\n",
      "initial_load/movies/movies.json 52361 bytes\n"
     ]
    }
   ],
   "source": [
    "list_obj_s3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c8a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Subido correctamente a s3://dai03rt-proyecto/initial_load/genres/genres.parquet'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_data_s3(records=movie_genres, key=\"initial_load/genres/genres.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a3c82c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 28, 'name': 'Action'},\n",
       " {'id': 12, 'name': 'Adventure'},\n",
       " {'id': 16, 'name': 'Animation'},\n",
       " {'id': 35, 'name': 'Comedy'},\n",
       " {'id': 80, 'name': 'Crime'},\n",
       " {'id': 99, 'name': 'Documentary'},\n",
       " {'id': 18, 'name': 'Drama'},\n",
       " {'id': 10751, 'name': 'Family'},\n",
       " {'id': 14, 'name': 'Fantasy'},\n",
       " {'id': 36, 'name': 'History'},\n",
       " {'id': 27, 'name': 'Horror'},\n",
       " {'id': 10402, 'name': 'Music'},\n",
       " {'id': 9648, 'name': 'Mystery'},\n",
       " {'id': 10749, 'name': 'Romance'},\n",
       " {'id': 878, 'name': 'Science Fiction'},\n",
       " {'id': 10770, 'name': 'TV Movie'},\n",
       " {'id': 53, 'name': 'Thriller'},\n",
       " {'id': 10752, 'name': 'War'},\n",
       " {'id': 37, 'name': 'Western'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_parquet = load_data_s3(\"initial_load/genres/genres.parquet\")\n",
    "genres_parquet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
